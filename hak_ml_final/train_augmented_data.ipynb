{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This notebook's main goal is to expand the training dataset by augmentation means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import h3\n",
    "import folium\n",
    "import osmnx as ox\n",
    "from shapely import wkt\n",
    "from folium.plugins import HeatMap\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import LineString\n",
    "from shapely.geometry import MultiPolygon\n",
    "import os\n",
    "from area import area\n",
    "from pyproj import Geod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOSCOW = \"Moscow\"\n",
    "RES1 = 8 # the resolution of the hypothetical hexagones to build for each given point\n",
    "RES2 = 9 # resolution 1 degree larger: provide hexagons that will serve as building blocks for the extrapulated hexagones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_cols = ['h3', 'lat', 'lng']\n",
    "\n",
    "# given a geometry it returns lat, lng and h3 index with resolution 8\n",
    "def get_h3_geo(g, res):\n",
    "    lng = g.x if isinstance(g, Point) else g.centroid.x     \n",
    "    lat = g.y if isinstance(g, Point) else g.centroid.y\n",
    "    h3_addr = h3.geo_to_h3(lat=lat, lng=lng, resolution=res)\n",
    "    return h3_addr, lat, lng\n",
    "\n",
    "# funciton to apply on a dataframe\n",
    "def get_h3(row, res):\n",
    "    g = row['geometry']\n",
    "    row['h3'], row['lat'], row['lng'] = get_h3_geo(g, res)\n",
    "    return row\n",
    "\n",
    "def osm_query(city, tag):\n",
    "    gdf = ox.geometries_from_place(city, tag).reset_index()\n",
    "    print(gdf.shape)\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "def get_data(tag, n, res):\n",
    "    g = osm_query(MOSCOW, tag)\n",
    "    \n",
    "    size = len(g)\n",
    "    indices = random.choices(range(size), k=n)\n",
    "    \n",
    "    indices = list(set(indices))\n",
    "    print(len(indices))\n",
    "    \n",
    "    def get_data_get_h3(row):\n",
    "        return get_h3(row, res)\n",
    "    \n",
    "    return g.apply(get_data_get_h3, axis=1).loc[indices, def_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to extract points that satisfy the following tags\n",
    "tags_education = [{\"amenity\": \"college\"}, {\"amenity\": \"school\"}, {\"amenity\": \"university\"}]\n",
    "tags_parking = [{\"amenity\":\"parking\"}]\n",
    "tags_bus = [{\"highway\":\"bus_stop\"}]\n",
    "tags_financial = [{\"amenity\": \"atm\"}, {\"amenity\": \"bank\"}, {\"amenity\": \"bureau_de_change\"}]\n",
    "acc_tags = [{'building' : 'apartments'}, {'building' : 'hotel'}, {'building' : 'house'}]\n",
    "commercial_tags = [{'building' : 'commercial'}, {'building' : 'retail'}, {'building' : 'supermarket'}] # excludes kiosks\n",
    "health_care_tags = [{\"amenity\":\"hospital\"}, {\"amenity\": \"clinic\"}, {\"amenity\": \"pharmacy\"}]\n",
    "enter_tags = [{\"amenity\":\"nightclub\"}, {\"amenity\": \"cinema\"}, {\"amenity\": \"community_centre\"}]\n",
    "sus_tags = [{\"amenity\":\"bar\"}, {\"amenity\":\"cafe\"}, {\"amenity\":\"fast_food\"}, {\"amenity\":\"food_court\"}, {\"amenity\":\"pub\"}, {\"amenity\":\"restaurant\"}]\n",
    "highway_tags = [{\"highway\":\"primary\"}, {\"highway\":\"secondary\"}, {\"highway\":\"tertiary\"}, {\"highway\":\"residential\"}, {\"highway\":\"pedestrian\"}]\n",
    "\n",
    "religious_tags = [{\"building\":\"church\"}]\n",
    "parks_tags = [{\"boundary\": \"national_park\"}, {\"boundary\":\"protected_area\"}]\n",
    "air_tags = [{\"aeroway\": \"aerodrome\"}, {\"aeroway\": \"apron\"}, {\"aeroway\": \"hangar\"}] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tags = [{\"amenity\": \"college\"}, {\"amenity\": \"school\"}, {\"amenity\": \"university\"}, {\"amenity\":\"parking\"}, {\"highway\":\"bus_stop\"}, \n",
    "            {\"amenity\": \"atm\"}, {\"amenity\": \"bank\"}, {\"amenity\": \"bureau_de_change\"}, {'building' : 'apartments'}, {'building' : 'hotel'}, {'building' : 'house'},\n",
    "            {'building' : 'commercial'}, {'building' : 'retail'}, {'building' : 'supermarket'}, {\"amenity\":\"hospital\"}, {\"amenity\": \"clinic\"}, {\"amenity\": \"pharmacy\"}, \n",
    "            {\"amenity\":\"nightclub\"}, {\"amenity\": \"cinema\"}, {\"amenity\": \"community_centre\"}, \n",
    "            {\"amenity\":\"bar\"}, {\"amenity\":\"cafe\"}, {\"amenity\":\"fast_food\"}, {\"amenity\":\"food_court\"}, {\"amenity\":\"pub\"}, {\"amenity\":\"restaurant\"}, \n",
    "            {\"highway\":\"primary\"}, {\"highway\":\"secondary\"}, {\"highway\":\"tertiary\"}, {\"highway\":\"residential\"}, {\"highway\":\"pedestrian\"},\n",
    "            {\"building\":\"church\"}, \n",
    "            {\"boundary\": \"national_park\"}, {\"boundary\":\"protected_area\"}, {\"aeroway\": \"hangar\"}, \n",
    "            {\"amenity\": \"social_facility\"}, {\"amenity\": \"nursing_home\"}, {\"amenity\": \"grave_yard\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_tags = [{\"amenity\": \"social_facility\"}, {\"amenity\": \"nursing_home\"}, {\"amenity\": \"grave_yard\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = get_data(tags_education[0], 500, RES2)\n",
    "# d_h3_9 = set(d['h3'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_9_h3 = set(data_9['h3'].values)\n",
    "\n",
    "# print(len(data_9_h3.intersection(d_h3_9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_9 = pd.read_excel(os.path.join(\"osm_features\", f\"training_data_{str(RES2)}.xlsx\")).set_index('h3')\n",
    "h3_9_set = set(list(data_9.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hexagone_datapoint(row):\n",
    "    h3_9 = row['h3'] \n",
    "    # gets all seven hexagones with distance less or equal to 1: the ones we need to build the extrapulated hexagone\n",
    "    neighbors_h3s = h3.k_ring(h3_9, 1)\n",
    "    col_dict = {} \n",
    "    common_indices =  set(list(neighbors_h3s)).intersection(h3_9_set)\n",
    "    if len(common_indices) > 0:\n",
    "        row_data = data_9.drop(columns=['lat', 'lng']).loc[list(common_indices), :]        \n",
    "        for col in row_data.columns:\n",
    "            col_dict[col] = row_data[col].sum()\n",
    "        try:\n",
    "            df = pd.DataFrame(col_dict, index=list(range(1)))\n",
    "        except IndexError:\n",
    "            return \n",
    "        # add the coordinates\n",
    "        df['lat'] = row['lat']\n",
    "        df['lng'] = row['lng']\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = get_data(tags_education[0], 10, RES2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_feat = pd.DataFrame(data=[], columns=data_9.columns)\n",
    "# for id, row in test.iterrows():\n",
    "#     new_row = get_hexagone_datapoint(row)\n",
    "#     test_feat = pd.concat([test_feat, new_row])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def osm_augmented_tag(tag):\n",
    "    tag_data = get_data(tag, 300, RES2)\n",
    "    tag_feat = pd.DataFrame(data=[], columns=data_9.columns)\n",
    "    for _ , row in tag_data.iterrows():\n",
    "        new_row = get_hexagone_datapoint(row)\n",
    "        if new_row is not None:\n",
    "            tag_feat = pd.concat([tag_feat, new_row])\n",
    "    return tag_feat\n",
    "\n",
    "def osm_augmented_all(all_tags):\n",
    "    augmented_osm_feats = pd.DataFrame(data=[], columns=data_9.columns)\n",
    "    for tag in all_tags:\n",
    "        print(tag)\n",
    "        augmented_osm_feats = pd.concat([augmented_osm_feats, osm_augmented_tag(tag)], ignore_index=True)\n",
    "    return augmented_osm_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional_aug_data = osm_augmented_all(add_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'amenity': 'college'}\n",
      "(281, 88)\n",
      "183\n",
      "{'amenity': 'school'}\n",
      "(1949, 152)\n",
      "281\n",
      "{'amenity': 'university'}\n",
      "(380, 194)\n",
      "216\n",
      "{'amenity': 'parking'}\n",
      "(15069, 139)\n",
      "299\n",
      "{'highway': 'bus_stop'}\n",
      "(9539, 115)\n",
      "292\n",
      "{'amenity': 'atm'}\n",
      "(2144, 91)\n",
      "283\n",
      "{'amenity': 'bank'}\n",
      "(2047, 118)\n",
      "284\n",
      "{'amenity': 'bureau_de_change'}\n",
      "(129, 39)\n",
      "113\n",
      "{'building': 'apartments'}\n",
      "(30283, 168)\n",
      "297\n",
      "{'building': 'hotel'}\n",
      "(121, 108)\n",
      "110\n",
      "{'building': 'house'}\n",
      "(3040, 71)\n",
      "284\n",
      "{'building': 'commercial'}\n",
      "(1864, 179)\n",
      "278\n",
      "{'building': 'retail'}\n",
      "(2072, 205)\n",
      "271\n",
      "{'building': 'supermarket'}\n",
      "(19, 36)\n",
      "19\n",
      "{'amenity': 'hospital'}\n",
      "(264, 100)\n",
      "185\n",
      "{'amenity': 'clinic'}\n",
      "(1361, 158)\n",
      "269\n",
      "{'amenity': 'pharmacy'}\n",
      "(3483, 116)\n",
      "287\n",
      "{'amenity': 'nightclub'}\n",
      "(90, 43)\n",
      "86\n",
      "{'amenity': 'cinema'}\n",
      "(128, 76)\n",
      "111\n",
      "{'amenity': 'community_centre'}\n",
      "(323, 123)\n",
      "198\n",
      "{'amenity': 'bar'}\n",
      "(674, 93)\n",
      "259\n",
      "{'amenity': 'cafe'}\n",
      "(3743, 189)\n",
      "286\n",
      "{'amenity': 'fast_food'}\n",
      "(3222, 186)\n",
      "290\n",
      "{'amenity': 'food_court'}\n",
      "(59, 43)\n",
      "59\n",
      "{'amenity': 'pub'}\n",
      "(329, 81)\n",
      "199\n",
      "{'amenity': 'restaurant'}\n",
      "(2468, 163)\n",
      "285\n",
      "{'highway': 'primary'}\n",
      "(3732, 133)\n",
      "290\n",
      "{'highway': 'secondary'}\n",
      "(8344, 173)\n",
      "293\n",
      "{'highway': 'tertiary'}\n",
      "(7545, 185)\n",
      "296\n",
      "{'highway': 'residential'}\n",
      "(4983, 174)\n",
      "295\n",
      "{'highway': 'pedestrian'}\n",
      "(631, 126)\n",
      "241\n",
      "{'building': 'church'}\n",
      "(350, 107)\n",
      "195\n",
      "{'boundary': 'national_park'}\n",
      "(1, 5)\n",
      "1\n",
      "{'boundary': 'protected_area'}\n",
      "(26, 62)\n",
      "26\n",
      "{'aeroway': 'hangar'}\n",
      "(25, 8)\n",
      "25\n",
      "{'amenity': 'social_facility'}\n",
      "(239, 79)\n",
      "167\n",
      "{'amenity': 'nursing_home'}\n",
      "(1, 8)\n",
      "1\n",
      "{'amenity': 'grave_yard'}\n",
      "(11, 19)\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "augmented_osm_data = osm_augmented_all(all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_osm_data.to_excel(os.path.join('osm_features', 'augmented_data_8.xlsx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Population and Metro stations data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first set the augmented_osm_data h3 column to resolution 8\n",
    "def set_h3_to_8(row):\n",
    "    row['h3'] = h3.geo_to_h3(lat=row['lat'], lng=row['lng'], resolution=RES1)\n",
    "    return row\n",
    "\n",
    "def set_h3_to_9(row):\n",
    "    row['h3'] = h3.geo_to_h3(lat=row['lat'], lng=row['lng'], resolution=RES2) # make sure to use RES2 and not RES1\n",
    "    return row\n",
    "    \n",
    "\n",
    "augmented_osm_data = augmented_osm_data.apply(set_h3_to_8, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to add the population and metro station data\n",
    "pop_metro = pd.read_excel(\"training_data_y.xlsx\").loc[:, ['h3', 'TotalPassengers', 'population']] # the h3 index of this dataset is 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the h3 index in the\n",
    "augmented_data = pd.merge(augmented_osm_data, pop_metro, on='h3', how='left')\n",
    "# print(augmented_data.isna().sum())\n",
    "augmented_data = augmented_data.drop('h3', axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_data = augmented_data.drop_duplicates(subset=['lat', 'lng'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_data.to_excel(\"augmented_no_y.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first import the file with the count of postamats in each hexagon of resolution 9\n",
    "post_count_9 = pd.read_excel('postmats_count_9.xlsx').set_index('h3')\n",
    "\n",
    "augmented_data = augmented_data.apply(set_h3_to_9, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1246\n"
     ]
    }
   ],
   "source": [
    "aug_h3_9 = set(augmented_data['h3'].values)\n",
    "pos_h3_9 = set(list(post_count_9.index))\n",
    "\n",
    "print(len(pos_h3_9.intersection(aug_h3_9)))\n",
    "def posts_count_datapoint(row):\n",
    "    h3_9 = row['h3']\n",
    "    neighbors_h3 = h3.k_ring(h3_9, 1)\n",
    "    count = 0\n",
    "    for n in neighbors_h3:\n",
    "        try:\n",
    "            count += post_count_9.loc[n, 'y']\n",
    "        except KeyError:\n",
    "            pass\n",
    "    row['y'] = count\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6226\n"
     ]
    }
   ],
   "source": [
    "augmented_data = augmented_data.apply(posts_count_datapoint, axis=1)\n",
    "print((augmented_data['y'] > 0).sum())\n",
    "augmented_data.to_excel('augmented_data_y.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmented_data['y'].value_counts()\n",
    "original_training_data = pd.read_excel('training_data_y.xlsx').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "955\n"
     ]
    }
   ],
   "source": [
    "print((original_training_data['y'] > 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1120\n"
     ]
    }
   ],
   "source": [
    "print((original_training_data['y'] <= 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_t_d = pd.concat([original_training_data, augmented_data], ignore_index=True)  \n",
    "# pd.read_excel('final_training_data_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9635, 38)\n",
      "7181\n"
     ]
    }
   ],
   "source": [
    "print(f_t_d.shape)\n",
    "print((f_t_d['y'] > 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2454, 38)\n"
     ]
    }
   ],
   "source": [
    "df_neg = f_t_d[f_t_d['y'] <= 0]\n",
    "print(df_neg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = f_t_d[f_t_d['y'] > 0]\n",
    "random_indices = random.sample(list(f_t_d.index), 3600)\n",
    "df_pos = f_t_d.loc[random_indices, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_t_d = pd.concat([df_pos, df_neg], ignore_index=True)#.drop(columns=['h3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_t_d.to_excel('final_training_dataset.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
