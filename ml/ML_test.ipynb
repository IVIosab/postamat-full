{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostClassifier\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOLUTION = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_8 = os.path.join(f\"final_training_dataset.xlsx\")\n",
    "data = pd.read_excel(os.path.join(data_8), usecols=lambda x: 'Unnamed' not in x)\n",
    "data_org = data.copy()\n",
    "# first drop the h3, lat and lng attributes\n",
    "data.drop(columns=['h3', 'lat', 'lng'], inplace=True)\n",
    "# consider this as a classification problem\n",
    "data['y'] = (data['y'] > 0).astype(int)\n",
    "data = data.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['y']\n",
    "data.pop('y')\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = data.copy()\n",
    "y_train =  y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_excel('test_data.xlsx',usecols=lambda x: 'Unnamed' not in x)\n",
    "df_predict = df_test.copy()\n",
    "df_predict.drop(columns=df.columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.loc[:, df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (df.columns == df_test.columns).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to apply the same function on both train and test datasets\n",
    "def apply(function, df_train, df_test, axis=1):\n",
    "    df_train = df_train.apply(function, axis=axis)\n",
    "    df_test = df_test.apply(function, axis=axis)\n",
    "    return df_train, df_test\n",
    "\n",
    "def drop(cols, df_train, df_test):\n",
    "    if isinstance(cols, str):\n",
    "        cols = [cols]\n",
    "    return df_train.drop(columns=cols), df_test.drop(columns=cols)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide(a, b):\n",
    "    return a / b if b != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_feat(df, col):\n",
    "    sns.displot(df, x=col, hue='y', palette='dark')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "def make_mi_scores(X, y):\n",
    "    X = X.copy()\n",
    "    # discrete features are the ones with type int\n",
    "    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n",
    "\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "\n",
    "def plot_mi_scores(scores):\n",
    "    scores = scores.sort_values(ascending=True)\n",
    "    width = np.arange(len(scores))\n",
    "    ticks = list(scores.index)\n",
    "    plt.barh(width, scores)\n",
    "    plt.yticks(width, ticks)\n",
    "    plt.title(\"Mutual Information Scores\")\n",
    "    \n",
    "def mi_scores(x, y):\n",
    "    mi_scores = make_mi_scores(x, y)\n",
    "    plot_mi_scores(mi_scores)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df.columns:\n",
    "    if len(df[df[c] != 0]) == 0:\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict = {}\n",
    "for c in df.columns:\n",
    "    # for each column: filter by rows who do not have zero at that column and retrive the column\n",
    "    q3, q1 = np.percentile(df[df[c] != 0][c], [75, 25])\n",
    "    iqr = q3 - q1\n",
    "    min_v = q1 - 1.5 * iqr\n",
    "    max_v = q3 + 1.5 * iqr\n",
    "    out_dict[c] = (min_v, max_v)\n",
    "\n",
    "\n",
    "cols = df.columns\n",
    "def fix_outliers(row):\n",
    "    for c in cols:\n",
    "        v = row[c]\n",
    "        min_v, max_v = out_dict[c]\n",
    "        if v != 0 and v > max_v:\n",
    "            row[c] = max_v\n",
    "        elif v != 0 and v < min_v:\n",
    "            row[c] = min_v\n",
    "    return row\n",
    "\n",
    "df_t = df.apply(fix_outliers, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_s = 'bus_count'\n",
    "bus_f = 'bus_freq_count'\n",
    "metro  = 'TotalPassengers'\n",
    "def set_tranport(row):\n",
    "    row['transport'] = (row[bus_s] + 2) * np.sqrt(np.log(row[bus_f] + 2) ) + row[metro]\n",
    "    return row\n",
    "\n",
    "a_a = 'accomodation_area'\n",
    "a_c = 'accomodation_count'\n",
    "pop = 'population'\n",
    "\n",
    "def get_acc_feats(row):\n",
    "    row['density'] = divide(row[pop], row[a_a])\n",
    "    row['app_area'] = divide(row[a_a], row[a_c]) \n",
    "    row[a_a] / row[a_c] if row[a_c] != 0 else 0\n",
    "    return row\n",
    "# set accomodation and transport\n",
    "df, df_test = apply(get_acc_feats, df, df_test)\n",
    "df, df_test = apply(set_tranport, df, df_test)\n",
    "df, df_test = drop([\"count_highway_pedestrian\", \"length_highway_pedestrian\"], df, df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['y'] = y_train\n",
    "# for c in df.loc[:, \"app_area\":].columns:\n",
    "#     pdf_feat(df, c)\n",
    "# df.pop('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conclusions\n",
    "The columns should receive different treatments:\n",
    "1. boxcox transformation:\n",
    "    * bus\\_frequency\\_count\n",
    "    * education\\_area\n",
    "    * parking\\_area\n",
    "    * accomodation\\_count\n",
    "    * accomodation\\_area\n",
    "    * highway\\_primary \n",
    "    * count\\_h\\_2\n",
    "    * c\\_h\\_2\n",
    "    * c\\_h\\_r\n",
    "    * density\n",
    "    * app\\_area\n",
    "2. discretization:\n",
    "    * education\\_count\n",
    "    * fianacial\\_count\n",
    "    * commercial\\_count\n",
    "    * comercial\\_area\n",
    "    * health\\_care\\_count\n",
    "    * sustenance\\_count\n",
    "    * l\\_h\\_2\n",
    "    * l\\_h\\_3\n",
    "    * l\\_h\\_r\n",
    "3. nothing:\n",
    "    * parking\\_count\n",
    "    * bus\\_count\n",
    "    * entertainment\\_count\n",
    "    * population\n",
    "4. dropped:\n",
    "    * financial\\_area\n",
    "    * health\\_care\\_area\n",
    "    * entertainment\\_area\n",
    "    * sustenance\\_area\n",
    "    * sports, government\n",
    "    * TotalPassengers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the necessary transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "# first let's drop some columns:\n",
    "drop_columns = [\"financial_area\", \"health_care_area\", \"entertainment_area\", \"sustenance_area\", \n",
    "                \"sports_count\", \"sports_area\", \"government_area\", \"government_count\", metro, bus_f]\n",
    "\n",
    "box_cox_cols = [\"education_area\", \"parking_area\", \"accomodation_count\", \"accomodation_area\",\n",
    "                 \"count_highway_secondary\", \"length_highway_secondary\",\n",
    "                \"count_highway_residential\", \"density\", \"app_area\", \"length_highway_tertiary\"]\n",
    "discretize_cols = [\"count_highway_primary\", \"length_highway_primary\", \"education_count\", \"financial_count\", \"commercial_count\", \"commercial_area\", \"health_care_count\", \n",
    "                   \"sustenance_count\", \"length_highway_secondary\", \"length_highway_tertiary\", \"length_highway_residential\"]\n",
    "\n",
    "# drop\n",
    "df, df_test = drop(drop_columns, df, df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform with boxcox\n",
    "for c in box_cox_cols:\n",
    "    df[c] ,_params = st.boxcox(df[c] + 1)\n",
    "    df_test[c] = st.boxcox(df_test[c] + 1, _params)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discretize\n",
    "from feature_engine.discretisation import DecisionTreeDiscretiser\n",
    "discretize_cols\n",
    "disc = DecisionTreeDiscretiser(cv=3, param_grid={\"max_depth\": [2, 3], \"random_state\":[11]} , random_state=11, scoring='precision', variables=discretize_cols, regression=False)\n",
    "\n",
    "# fit the transformer\n",
    "df_t= disc.fit_transform(df, y_train)\n",
    "df_test_t = pd.DataFrame(disc.transform(df_test), columns=df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (df_test_t.columns == df_t.columns).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_t.copy()\n",
    "df_test = df_test_t.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6054, 25), (4905, 25))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic = [\"transport\", \"bus_count\", \n",
    "           \"parking_count\", \"parking_area\", \"count_highway_tertiary\" , \n",
    "           \"count_highway_residential\", \"length_highway_tertiary\",\n",
    "           \"length_highway_residential\",\"count_highway_secondary\",\n",
    "           \"length_highway_secondary\",\"length_highway_primary\",\"count_highway_primary\"]\n",
    "population = [col for col in df.columns if col not in traffic]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_scores = make_mi_scores(df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_8 = list(mi_scores.index)[:9]\n",
    "top_8.remove('accomodation_area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_8 = [\"accomodation_area\"             \n",
    "# ,\"density\"                       \n",
    "# ,\"accomodation_count\"            \n",
    "# ,\"app_area\"                      \n",
    "# ,\"transport\"                     \n",
    "# ,\"bus_count\"                     \n",
    "# , \"education_count\"               \n",
    "# , \"population\" ]                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['density', 'transport', 'parking_area', 'education_area', 'app_area', 'population', 'bus_count', 'count_highway_tertiary', 'count_highway_residential', 'count_highway_secondary', 'length_highway_secondary', 'count_highway_primary', 'length_highway_residential', 'length_highway_primary', 'length_highway_tertiary', 'parking_count', 'accomodation_count']\n",
      "['education_count', 'entertainment_count', 'density', 'transport', 'education_area', 'app_area', 'population', 'bus_count', 'financial_count', 'accomodation_area', 'commercial_area', 'commercial_count', 'sustenance_count', 'health_care_count', 'parking_count', 'accomodation_count']\n"
     ]
    }
   ],
   "source": [
    "traffic_cols = list(set(top_8).union(traffic)) \n",
    "population_cols = list(set(top_8).union(population))\n",
    "print(traffic_cols)\n",
    "print(population_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_traffic = df.loc[:, traffic_cols]\n",
    "df_test_traffic = df_test.loc[:, traffic_cols]\n",
    "\n",
    "df_pop = df.loc[:, population_cols]\n",
    "df_test_pop = df_test.loc[:, population_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def apply_PCA(df, df_test):\n",
    "    ss = StandardScaler()\n",
    "    pca = PCA(n_components=0.95)\n",
    "\n",
    "    df_s = pd.DataFrame(ss.fit_transform(df), columns=df.columns)\n",
    "    df_test_s = pd.DataFrame(ss.transform(df_test), columns=df_test.columns)\n",
    "\n",
    "    df_p = pd.DataFrame(pca.fit_transform(df_s))\n",
    "    df_test_p = pd.DataFrame(pca.transform(df_test_s))\n",
    "\n",
    "    df = df_p.copy()\n",
    "    df_test = df_test_p.copy()\n",
    "    return df, df_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, df_test = apply_PCA(df, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop, df_test_pop = apply_PCA(df_pop, df_test_pop)\n",
    "df_traffic, df_test_traffic = apply_PCA(df_traffic, df_test_traffic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = pickle.load(open(\"best_model.sav\", 'rb'))\n",
    "# print(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1.0,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, gamma=0.5, gpu_id=-1, grow_policy='depthwise',\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.02, max_bin=256, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=600,\n",
      "              n_jobs=1, nthread=1, num_parallel_tree=1, predictor='auto',\n",
      "              random_state=42, reg_alpha=0, ...)\n"
     ]
    }
   ],
   "source": [
    "best_model = pickle.load(open(os.path.join(\"models\",\"XGB.sav\"), 'rb'))\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_save(df, y_train, df_test, model_name, file_name):\n",
    "    best_model.fit(df, y_train)\n",
    "    y_pred = best_model.predict_proba(df_test)\n",
    "    predictions = (y_pred[:, 1].tolist())\n",
    "    \n",
    "    df_p = df_predict.copy()\n",
    "    df_p['rating'] = [p * 100 for p in predictions]\n",
    "    df_p['model'] = [model_name for _ in predictions]\n",
    "    df_p = df_p.sort_values(by='rating')\n",
    "    \n",
    "    new_index = pd.Index(list(range(len(df_p))))\n",
    "    df_p = df_p.set_index(new_index)\n",
    "    df_p = df_p.reset_index() \n",
    "    df_p = df_p.rename(columns={\"index\":\"rank\"}) \n",
    "    df_p['rank'] = df_p['rank'] + 1\n",
    "    df_p.to_excel(f\"{file_name}.xlsx\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:10:23] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:10:37] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:10:47] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_save(df, y_train, df_test, \"main\", \"main\")\n",
    "predict_save(df_pop, y_train, df_test_pop, \"Population\", \"Population\")\n",
    "predict_save(df_traffic, y_train, df_test_traffic, \"Traffic\", \"Traffic\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "ds_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
